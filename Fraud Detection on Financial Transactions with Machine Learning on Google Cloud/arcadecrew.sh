#!/bin/bash
BLACK_TEXT=$'\033[0;90m'
RED_TEXT=$'\033[0;91m'
GREEN_TEXT=$'\033[0;92m'
YELLOW_TEXT=$'\033[0;93m'
BLUE_TEXT=$'\033[0;94m'
MAGENTA_TEXT=$'\033[0;95m'
CYAN_TEXT=$'\033[0;96m'
WHITE_TEXT=$'\033[0;97m'
DIM_TEXT=$'\033[2m'
STRIKETHROUGH_TEXT=$'\033[9m'
BOLD_TEXT=$'\033[1m'
RESET_FORMAT=$'\033[0m'

clear

echo
echo "${CYAN_TEXT}${BOLD_TEXT}===================================${RESET_FORMAT}"
echo "${CYAN_TEXT}${BOLD_TEXT}üöÄ     INITIATING EXECUTION     üöÄ${RESET_FORMAT}"
echo "${CYAN_TEXT}${BOLD_TEXT}===================================${RESET_FORMAT}"
echo

echo "${GREEN_TEXT}${BOLD_TEXT}üîë Setting your Google Cloud Project ID...${RESET_FORMAT}"
export PROJECT_ID=$(gcloud config get-value project)

echo "${BLUE_TEXT}${BOLD_TEXT}‚òÅÔ∏è Preparing to copy the dataset from Cloud Storage...${RESET_FORMAT}"
gsutil cp gs://spls/gsp774/archive.zip .

echo "${MAGENTA_TEXT}${BOLD_TEXT}üì¶ Unzipping the downloaded archive...${RESET_FORMAT}"
unzip archive.zip

echo "${CYAN_TEXT}${BOLD_TEXT}üìù Assigning the data file variable...${RESET_FORMAT}"
export DATA_FILE=PS_20174392719_1491204439457_log.csv

echo "${RED_TEXT}${BOLD_TEXT}üìÅ Creating a new BigQuery dataset named 'finance'...${RESET_FORMAT}"
bq mk --dataset $PROJECT_ID:finance

echo "${YELLOW_TEXT}${BOLD_TEXT}ü™£ Setting up a new Cloud Storage bucket for your project...${RESET_FORMAT}"
gsutil mb gs://$PROJECT_ID

echo "${GREEN_TEXT}${BOLD_TEXT}‚¨ÜÔ∏è Uploading the data file to your Cloud Storage bucket...${RESET_FORMAT}"
gsutil cp $DATA_FILE gs://$PROJECT_ID

echo "${BLUE_TEXT}${BOLD_TEXT}üìä Loading the data into BigQuery table 'finance.fraud_data'...${RESET_FORMAT}"
bq load --autodetect --source_format=CSV --max_bad_records=100000 finance.fraud_data gs://$PROJECT_ID/$DATA_FILE

echo "${MAGENTA_TEXT}${BOLD_TEXT}üîé Summarizing transactions by type and fraud status...${RESET_FORMAT}"
bq query --use_legacy_sql=false \
"SELECT type, isFraud, count(*) as cnt
 FROM \`finance.fraud_data\`
 GROUP BY isFraud, type
 ORDER BY type"

echo "${CYAN_TEXT}${BOLD_TEXT}üí° Checking fraud counts for 'CASH_OUT' and 'TRANSFER' transactions...${RESET_FORMAT}"
bq query --use_legacy_sql=false \
'SELECT isFraud, count(*) as cnt
FROM `finance.fraud_data`
WHERE type in ("CASH_OUT", "TRANSFER")
GROUP BY isFraud'

echo "${RED_TEXT}${BOLD_TEXT}üí∞ Displaying the top 10 largest transactions...${RESET_FORMAT}"
bq query --use_legacy_sql=false \
"SELECT *
 FROM \`finance.fraud_data\`
 ORDER BY amount DESC
 LIMIT 10"

echo "${YELLOW_TEXT}${BOLD_TEXT}üß™ Creating a sampled dataset with engineered features...${RESET_FORMAT}"
bq query --use_legacy_sql=false \
'CREATE OR REPLACE TABLE finance.fraud_data_sample AS
SELECT
  type,
  amount,
  nameOrig,
  nameDest,
  oldbalanceOrg as oldbalanceOrig,  #standardize the naming.
  newbalanceOrig,
  oldbalanceDest,
  newbalanceDest,
# add new features:
  if(oldbalanceOrg = 0.0, 1, 0) as origzeroFlag,
  if(newbalanceDest = 0.0, 1, 0) as destzeroFlag,
  round((newbalanceDest-oldbalanceDest-amount)) as amountError,
  generate_uuid() as id,        #create a unique id for each transaction.
  isFraud
FROM finance.fraud_data
WHERE
# filter unnecessary transaction types:
  type in("CASH_OUT","TRANSFER") AND
# undersample:
  (isFraud = 1 or (RAND()< 10/100))'  # select 10% of the non-fraud cases

echo "${GREEN_TEXT}${BOLD_TEXT}‚úÇÔ∏è Splitting the data into test and model datasets...${RESET_FORMAT}"
bq query --use_legacy_sql=false \
"CREATE OR REPLACE TABLE finance.fraud_data_test AS
SELECT *
FROM finance.fraud_data_sample
where RAND() < 20/100"

bq query --use_legacy_sql=false \
"CREATE OR REPLACE TABLE finance.fraud_data_model AS
SELECT
*
FROM finance.fraud_data_sample  
EXCEPT distinct select * from finance.fraud_data_test"

echo "${BLUE_TEXT}${BOLD_TEXT}ü§ñ Training an unsupervised K-Means clustering model...${RESET_FORMAT}"
bq query --use_legacy_sql=false \
"CREATE OR REPLACE MODEL
  finance.model_unsupervised OPTIONS(model_type='kmeans', num_clusters=5) AS
SELECT
  amount, oldbalanceOrig, newbalanceOrig, oldbalanceDest, newbalanceDest, type, origzeroFlag, destzeroFlag, amountError
  FROM
  \`finance.fraud_data_model\`"

echo "${MAGENTA_TEXT}${BOLD_TEXT}üìà Reviewing fraud distribution across clusters...${RESET_FORMAT}"
bq query --use_legacy_sql=false \
'SELECT
  centroid_id, sum(isfraud) as fraud_cnt,  count(*) total_cnt
FROM
  ML.PREDICT(MODEL `finance.model_unsupervised`,
    (
    SELECT *
    FROM  `finance.fraud_data_test`))
group by centroid_id
order by centroid_id'

echo "${GREEN_TEXT}${BOLD_TEXT}üß† Training a supervised logistic regression model...${RESET_FORMAT}"
bq query --use_legacy_sql=false \
"CREATE OR REPLACE MODEL
  finance.model_supervised_initial
  OPTIONS(model_type='LOGISTIC_REG', INPUT_LABEL_COLS = ['isfraud']
  )
AS
SELECT
type, amount, oldbalanceOrig, newbalanceOrig, oldbalanceDest, newbalanceDest, isFraud
FROM finance.fraud_data_model"

echo "${CYAN_TEXT}${BOLD_TEXT}‚öñÔ∏è Retrieving weights from the logistic regression model...${RESET_FORMAT}"
bq query --use_legacy_sql=false \
'SELECT
  *
FROM
  ML.WEIGHTS(MODEL `finance.model_supervised_initial`,
    STRUCT(true AS standardize))'

echo "${RED_TEXT}${BOLD_TEXT}üîÆ Predicting fraud cases using the trained model...${RESET_FORMAT}"
bq query --use_legacy_sql=false \
'SELECT id, label as predicted, isFraud as actual
FROM
  ML.PREDICT(MODEL `finance.model_supervised_initial`,
   (
    SELECT  *
    FROM  `finance.fraud_data_test`
   )
  ), unnest(predicted_isfraud_probs) as p
where p.label = 1 and p.prob > 0.5'

echo
echo "${MAGENTA_TEXT}${BOLD_TEXT}üíñ IF YOU FOUND THIS HELPFUL, SUBSCRIBE ARCADE CREW! üëá${RESET_FORMAT}"
echo "${BLUE_TEXT}${BOLD_TEXT}${UNDERLINE_TEXT}https://www.youtube.com/@Arcade61432${RESET_FORMAT}"
echo
